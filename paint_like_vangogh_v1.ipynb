{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sys import stderr\n",
    "from functools import reduce\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Inputs \n",
    "file_content_image = '4vs1_eyes.jpg' \n",
    "file_style_image = 'self_portrait_sample_1.jpg'  \n",
    "\n",
    "\n",
    "## Parameters \n",
    "input_noise = 0.1     # proportion noise to apply to content image\n",
    "weight_style = 2e2 \n",
    "\n",
    "## Layers\n",
    "layer_content = 'conv4_2' \n",
    "layers_style = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
    "layers_style_weights = [0.2,0.2,0.2,0.2,0.2]\n",
    "\n",
    "## VGG19 model\n",
    "path_VGG19 = 'imagenet-vgg-verydeep-19.mat'\n",
    "# VGG19 mean for standardisation (RGB)\n",
    "VGG19_mean = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "\n",
    "## Reporting & writing checkpoint images\n",
    "# NB. the total # of iterations run will be n_checkpoints * n_iterations_checkpoint\n",
    "n_checkpoints = 5            # number of checkpoints\n",
    "n_iterations_checkpoint = 12   # learning iterations per checkpoint\n",
    "path_output = 'output_imgage'  # directory to write checkpoint images into\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Helper functions\n",
    "def imread(path):\n",
    "    return scipy.misc.imread(path).astype(np.float)   # returns RGB format\n",
    "\n",
    "def imsave(path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    scipy.misc.imsave(path, img)\n",
    "    \n",
    "def imgpreprocess(image):\n",
    "    image = image[np.newaxis,:,:,:]\n",
    "    return image - VGG19_mean\n",
    "\n",
    "def imgunprocess(image):\n",
    "    temp = image + VGG19_mean\n",
    "    return temp[0] \n",
    "\n",
    "# function to convert 2D greyscale to 3D RGB\n",
    "def to_rgb(im):\n",
    "    w, h = im.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = im\n",
    "    ret[:, :, 1] = im\n",
    "    ret[:, :, 2] = im\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Preprocessing\n",
    "# create output directory\n",
    "if not os.path.exists(path_output):\n",
    "    os.mkdir(path_output)\n",
    "\n",
    "# read in images\n",
    "img_content = imread(file_content_image) \n",
    "img_style = imread(file_style_image) \n",
    "\n",
    "# convert if greyscale\n",
    "if len(img_content.shape)==2:\n",
    "    img_content = to_rgb(img_content)\n",
    "\n",
    "if len(img_style.shape)==2:\n",
    "    img_style = to_rgb(img_style)\n",
    "\n",
    "# resize style image to match content\n",
    "img_style = scipy.misc.imresize(img_style, img_content.shape)\n",
    "\n",
    "# apply noise to create initial \"canvas\" \n",
    "noise = np.random.uniform(\n",
    "        img_content.mean()-img_content.std(), img_content.mean()+img_content.std(),\n",
    "        (img_content.shape)).astype('float32')\n",
    "img_initial = noise * input_noise + img_content * (1 - input_noise)\n",
    "\n",
    "# preprocess each\n",
    "img_content = imgpreprocess(img_content)\n",
    "img_style = imgpreprocess(img_style)\n",
    "img_initial = imgpreprocess(img_initial)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### BUILD VGG19 MODEL\n",
    "## with thanks to http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n",
    "\n",
    "VGG19 = scipy.io.loadmat(path_VGG19)\n",
    "VGG19_layers = VGG19['layers'][0]\n",
    "\n",
    "# help functions\n",
    "def _conv2d_relu(prev_layer, n_layer, layer_name):\n",
    "    # get weights for this layer:\n",
    "    weights = VGG19_layers[n_layer][0][0][2][0][0]\n",
    "    W = tf.constant(weights)\n",
    "    bias = VGG19_layers[n_layer][0][0][2][0][1]\n",
    "    b = tf.constant(np.reshape(bias, (bias.size)))\n",
    "    # create a conv2d layer\n",
    "    conv2d = tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b    \n",
    "    # add a ReLU function and return\n",
    "    return tf.nn.relu(conv2d)\n",
    "\n",
    "def _avgpool(prev_layer):\n",
    "    return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Setup network\n",
    "with tf.Session() as sess:\n",
    "    a, h, w, d     = img_content.shape\n",
    "    net = {}\n",
    "    net['input']   = tf.Variable(np.zeros((a, h, w, d), dtype=np.float32))\n",
    "    net['conv1_1']  = _conv2d_relu(net['input'], 0, 'conv1_1')\n",
    "    net['conv1_2']  = _conv2d_relu(net['conv1_1'], 2, 'conv1_2')\n",
    "    net['avgpool1'] = _avgpool(net['conv1_2'])\n",
    "    net['conv2_1']  = _conv2d_relu(net['avgpool1'], 5, 'conv2_1')\n",
    "    net['conv2_2']  = _conv2d_relu(net['conv2_1'], 7, 'conv2_2')\n",
    "    net['avgpool2'] = _avgpool(net['conv2_2'])\n",
    "    net['conv3_1']  = _conv2d_relu(net['avgpool2'], 10, 'conv3_1')\n",
    "    net['conv3_2']  = _conv2d_relu(net['conv3_1'], 12, 'conv3_2')\n",
    "    net['conv3_3']  = _conv2d_relu(net['conv3_2'], 14, 'conv3_3')\n",
    "    net['conv3_4']  = _conv2d_relu(net['conv3_3'], 16, 'conv3_4')\n",
    "    net['avgpool3'] = _avgpool(net['conv3_4'])\n",
    "    net['conv4_1']  = _conv2d_relu(net['avgpool3'], 19, 'conv4_1')\n",
    "    net['conv4_2']  = _conv2d_relu(net['conv4_1'], 21, 'conv4_2')     \n",
    "    net['conv4_3']  = _conv2d_relu(net['conv4_2'], 23, 'conv4_3')\n",
    "    net['conv4_4']  = _conv2d_relu(net['conv4_3'], 25, 'conv4_4')\n",
    "    net['avgpool4'] = _avgpool(net['conv4_4'])\n",
    "    net['conv5_1']  = _conv2d_relu(net['avgpool4'], 28, 'conv5_1')\n",
    "    net['conv5_2']  = _conv2d_relu(net['conv5_1'], 30, 'conv5_2')\n",
    "    net['conv5_3']  = _conv2d_relu(net['conv5_2'], 32, 'conv5_3')\n",
    "    net['conv5_4']  = _conv2d_relu(net['conv5_3'], 34, 'conv5_4')\n",
    "    net['avgpool5'] = _avgpool(net['conv5_4'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CONTENT LOSS: FUNCTION TO CALCULATE AND INSTANTIATION\n",
    "# with thanks to https://github.com/cysmith/neural-style-tf\n",
    "\n",
    "# Recode to be simpler: http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n",
    "def content_layer_loss(p, x):\n",
    "    _, h, w, d = [i.value for i in p.get_shape()]    # d: number of filters; h,w : height, width\n",
    "    M = h * w \n",
    "    N = d \n",
    "    K = 1. / (2. * N**0.5 * M**0.5)\n",
    "    loss = K * tf.reduce_sum(tf.pow((x - p), 2))\n",
    "    return loss\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(net['input'].assign(img_content))\n",
    "    p = sess.run(net[layer_content])  # Get activation output for content layer\n",
    "    x = net[layer_content]\n",
    "    p = tf.convert_to_tensor(p)\n",
    "    content_loss = content_layer_loss(p, x) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### STYLE LOSS: FUNCTION TO CALCULATE AND INSTANTIATION\n",
    "\n",
    "def style_layer_loss(a, x):\n",
    "    _, h, w, d = [i.value for i in a.get_shape()]\n",
    "    M = h * w \n",
    "    N = d \n",
    "    A = gram_matrix(a, M, N)\n",
    "    G = gram_matrix(x, M, N)\n",
    "    loss = (1./(4 * N**2 * M**2)) * tf.reduce_sum(tf.pow((G - A), 2))\n",
    "    return loss\n",
    "\n",
    "def gram_matrix(x, M, N):\n",
    "    F = tf.reshape(x, (M, N))                   \n",
    "    G = tf.matmul(tf.transpose(F), F)\n",
    "    return G\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(net['input'].assign(img_style))\n",
    "    style_loss = 0.\n",
    "    # style loss is calculated for each style layer and summed\n",
    "    for layer, weight in zip(layers_style, layers_style_weights):\n",
    "        a = sess.run(net[layer])\n",
    "        x = net[layer]\n",
    "        a = tf.convert_to_tensor(a)\n",
    "        style_loss += style_layer_loss(a, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 7586210304.000000\n",
      "  Number of iterations: 13\n",
      "  Number of functions evaluations: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 12/60\n",
      "  content loss: 4.65905e+07\n",
      "    style loss: 7.53962e+09\n",
      "    total loss: 7.58621e+09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 3141419520.000000\n",
      "  Number of iterations: 13\n",
      "  Number of functions evaluations: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 24/60\n",
      "  content loss: 5.18823e+07\n",
      "    style loss: 3.08954e+09\n",
      "    total loss: 3.14142e+09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 1944171392.000000\n",
      "  Number of iterations: 13\n",
      "  Number of functions evaluations: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 36/60\n",
      "  content loss: 5.5068e+07\n",
      "    style loss: 1.8891e+09\n",
      "    total loss: 1.94417e+09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 1418267904.000000\n",
      "  Number of iterations: 13\n",
      "  Number of functions evaluations: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 48/60\n",
      "  content loss: 5.66603e+07\n",
      "    style loss: 1.36161e+09\n",
      "    total loss: 1.41827e+09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS EXCEEDS LIMIT'\n",
      "  Objective function value: 1115344384.000000\n",
      "  Number of iterations: 13\n",
      "  Number of functions evaluations: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 60/60\n",
      "  content loss: 5.79875e+07\n",
      "    style loss: 1.05736e+09\n",
      "    total loss: 1.11534e+09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28389.577437877655"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Define loss function and minimise\n",
    "now = time.time()\n",
    "with tf.Session() as sess:\n",
    "    # loss function\n",
    "    L_total  = content_loss + weight_style * style_loss \n",
    "    \n",
    "    # instantiate optimiser\n",
    "    optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "      L_total, method='L-BFGS-B',\n",
    "      options={'maxiter': n_iterations_checkpoint})\n",
    "    \n",
    "#     init_op = tf.initialize_all_variables()\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    sess.run(net['input'].assign(img_initial))\n",
    "    for i in range(1,n_checkpoints+1):\n",
    "        # run optimisation\n",
    "        optimizer.minimize(sess)\n",
    "        \n",
    "        ## print costs\n",
    "        stderr.write('Iteration %d/%d\\n' % (i*n_iterations_checkpoint, n_checkpoints*n_iterations_checkpoint))\n",
    "        stderr.write('  content loss: %g\\n' % sess.run(content_loss))\n",
    "        stderr.write('    style loss: %g\\n' % sess.run(weight_style * style_loss))\n",
    "        stderr.write('    total loss: %g\\n' % sess.run(L_total))\n",
    "\n",
    "        ## write image\n",
    "        img_output = sess.run(net['input'])\n",
    "        img_output = imgunprocess(img_output)\n",
    "        timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_file = path_output+'/'+timestr+'_'+'%s.jpg' % (i*n_iterations_checkpoint)\n",
    "        imsave(output_file, img_output)\n",
    "time.time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
